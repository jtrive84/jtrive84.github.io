{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e10258a0-6f01-4537-8f0b-5b58494ea7bb",
   "metadata": {},
   "source": [
    "---\n",
    "title: GPU Acceleration with Polars LazyFrames\n",
    "date: 2025-10-29\n",
    "description: GPU Acceleration with Polars LazyFrames\n",
    "categories: [Python]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57086d12-8ace-4ebd-b89c-7a6d64706b72",
   "metadata": {},
   "source": [
    "In a previous post, I walked through how Polars can be used to process larger-than-memory datasets without needing to setup and maintain a dedicated compute cluster. This was accomplished by taking advantage of the Polars LazyFrame. Unlike a regular DataFrame which executes operations immediately, a LazyFrame builds up a logical query plan and defers execution until you explicitly call a method like `.collect()`. This allows Polars to optimize the entire query before running it by taking advantage of predicate and projection pushdown or reordering operations for efficiency. The benefit is that you can chain many transformations together without incurring intermediate computation costs, and when the query finally runs, Polars can execute it in a highly optimized fashion.\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"rapids-polars.png\" alt=\"\" width=\"800\">\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "Recent Polars releases have introduced GPU acceleration as a capability for scaling analytical workloads. From the user's perspective, all that needs to be done is to pass `engine=\"gpu\"` to `.collect()`, and existing queries will be executed on NVIDIA GPUs through cuDF and the RAPIDS ecosystem, resulting in significant speed-ups for many common DataFrame operations. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I encountered a bit of difficulty getting my environment configured to take advatntage of GPU acceleration (installing NVIDIA drivers, CUDA toolkit, etc.) I ultimately settled on using the [NVIDIA RAPIDS Docker image](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/rapidsai/containers/notebooks). The NVIDIA RAPIDS Docker images are pre-built containers that bundle the RAPIDS AI libraries (cuDF, cuML, cuGraph) together with CUDA, Python, and system dependencies. It's designed so you can quickly run RAPIDS on any machine with a compatible NVIDIA GPU without having to install and configure all the pieces manually. I opted for the RAPIDS notebook image which starts a JupyterLab notebook server by default. I can't recommend this approach enough. After pulling the image, the container can be initialized with:\n",
    "\n",
    "```sh\n",
    "$ docker run --rm -it --gpus all -p 8888:8888 -e JUPYTER_TOKEN=rapids \\\n",
    "  nvcr.io/nvidia/rapidsai/notebooks:25.08-cuda12.9-py3.13\n",
    "```\n",
    "<br>\n",
    "\n",
    "To ensure that the container environment can access the GPU(s) available on the host, run:\n",
    "\n",
    "```python\n",
    "import cupy as cp\n",
    "print(\"GPU available:\", cp.cuda.runtime.getDeviceCount())\n",
    "# Should be >=1.\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Alternatively, verify that the device is recognized from within the container using `nvidia-smi`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e62d5e2-4fe4-48f2-bf85-67c9e7140d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:16:07.377208Z",
     "iopub.status.busy": "2025-10-30T03:16:07.376983Z",
     "iopub.status.idle": "2025-10-30T03:16:07.894559Z",
     "shell.execute_reply": "2025-10-30T03:16:07.894027Z",
     "shell.execute_reply.started": "2025-10-30T03:16:07.377191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 30 03:16:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   20C    P8              9W /  300W |       1MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b99808-4494-4f05-8957-eeda08853fa2",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "The output indicates the system has 23GB of VRAM available. \n",
    "\n",
    "It is also necessary to install cudf-polars-cu12 to enable GPU acceleration in Polars since it provides the bridge between the Polars DataFrame engine and RAPIDS cuDF, which is NVIDIA's GPU-accelerated dataframe library built on CUDA 12. The standard Polars package runs entirely on CPU, but with cudf-polars-cu12 installed, Polars can transparently offload supported query operations to the GPU using the RAPIDS runtime. This package contains the CUDA-specific bindings, GPU kernels, and dependencies required for the Polars engine=\"gpu\" option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e4d26-a324-4d32-bb6a-16925afdf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install watermark cudf-polars-cu12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d8b6e-287c-4a54-aea8-a1bbaaac512a",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "To benchmark Polars CPU vs GPU performance, the New York City 311 Service Requests dataset (via NYC Open Data) will be used as the starting point. It is an ~16GB CSV file representing a city-wide log of non-emergency service requests submitted by residents of New York City since 2010. Each row corresponds to a single request. For example, a noise complaint, trash pickup issue, illegal dumping report or street-light outage, etc. It also includes key attributes such as when the request was created and when it was resolved, the type of complaint, the responding agency, location (latitude/longitude or borough/zip), and status. It is available for download on [Kaggle](https://www.kaggle.com/datasets/new-york-city/ny-311-service-requests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5332a-daec-45ce-80bf-c46640f15c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:16:42.124138Z",
     "iopub.status.busy": "2025-10-30T03:16:42.123926Z",
     "iopub.status.idle": "2025-10-30T03:16:42.521509Z",
     "shell.execute_reply": "2025-10-30T03:16:42.520987Z",
     "shell.execute_reply.started": "2025-10-30T03:16:42.124122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.9\n",
      "IPython version      : 8.37.0\n",
      "\n",
      "numpy : 1.26.4\n",
      "pandas: 2.3.1\n",
      "polars: 1.32.3\n",
      "\n",
      "Compiler    : GCC 13.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.10.244-240.970.amzn2.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "import polars as pl \n",
    "\n",
    "pl.Config(tbl_rows=30)\n",
    "pl.Config(float_precision=4)\n",
    "pl.Config(tbl_cols=None)\n",
    "\n",
    "%watermark -v -m -p numpy,pandas,polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399c9b5-5269-4be6-acf1-96da6aaeb8be",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "We start by creating a LazyFrame based on the service requests dataset, and display the first 5 records:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b22a7ba-04d3-448d-907c-e7a99349dca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:16:57.180809Z",
     "iopub.status.busy": "2025-10-30T03:16:57.180512Z",
     "iopub.status.idle": "2025-10-30T03:16:57.270753Z",
     "shell.execute_reply": "2025-10-30T03:16:57.270312Z",
     "shell.execute_reply.started": "2025-10-30T03:16:57.180792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>Borough</th><th>Complaint Type</th><th>Latitude</th><th>Longitude</th><th>resp_hours</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>2019</td><td>12</td><td>&quot;MANHATTAN&quot;</td><td>&quot;Street Condition&quot;</td><td>40.7457</td><td>-73.9877</td><td>null</td></tr><tr><td>2019</td><td>12</td><td>&quot;BROOKLYN&quot;</td><td>&quot;Noise - Commercial&quot;</td><td>40.5965</td><td>-73.9777</td><td>null</td></tr><tr><td>2019</td><td>12</td><td>&quot;BROOKLYN&quot;</td><td>&quot;Noise - Residential&quot;</td><td>40.6606</td><td>-73.8835</td><td>null</td></tr><tr><td>2019</td><td>12</td><td>&quot;QUEENS&quot;</td><td>&quot;Noise - Residential&quot;</td><td>40.7600</td><td>-73.8069</td><td>null</td></tr><tr><td>2019</td><td>12</td><td>&quot;QUEENS&quot;</td><td>&quot;Illegal Parking&quot;</td><td>40.7295</td><td>-73.7300</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────┬───────┬───────────┬─────────────────────┬──────────┬───────────┬────────────┐\n",
       "│ year ┆ month ┆ Borough   ┆ Complaint Type      ┆ Latitude ┆ Longitude ┆ resp_hours │\n",
       "│ ---  ┆ ---   ┆ ---       ┆ ---                 ┆ ---      ┆ ---       ┆ ---        │\n",
       "│ i64  ┆ i64   ┆ str       ┆ str                 ┆ f64      ┆ f64       ┆ i64        │\n",
       "╞══════╪═══════╪═══════════╪═════════════════════╪══════════╪═══════════╪════════════╡\n",
       "│ 2019 ┆ 12    ┆ MANHATTAN ┆ Street Condition    ┆ 40.7457  ┆ -73.9877  ┆ null       │\n",
       "│ 2019 ┆ 12    ┆ BROOKLYN  ┆ Noise - Commercial  ┆ 40.5965  ┆ -73.9777  ┆ null       │\n",
       "│ 2019 ┆ 12    ┆ BROOKLYN  ┆ Noise - Residential ┆ 40.6606  ┆ -73.8835  ┆ null       │\n",
       "│ 2019 ┆ 12    ┆ QUEENS    ┆ Noise - Residential ┆ 40.7600  ┆ -73.8069  ┆ null       │\n",
       "│ 2019 ┆ 12    ┆ QUEENS    ┆ Illegal Parking     ┆ 40.7295  ┆ -73.7300  ┆ null       │\n",
       "└──────┴───────┴───────────┴─────────────────────┴──────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lf = pl.scan_csv(\"311-service-requests.csv\")\n",
    "\n",
    "# Display the first 5 rows.\n",
    "first5 = lf.head(5).collect()\n",
    "\n",
    "first5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373d5dd-8776-480f-ab3c-831ddc485104",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "We also obtain a count of the number of rows in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77e0b32-c0ca-4692-9070-4924b64e93c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:17:11.574069Z",
     "iopub.status.busy": "2025-10-30T03:17:11.573862Z",
     "iopub.status.idle": "2025-10-30T03:17:11.728286Z",
     "shell.execute_reply": "2025-10-30T03:17:11.727811Z",
     "shell.execute_reply.started": "2025-10-30T03:17:11.574053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311-service-requests.csv: 21,960,000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = lf.select(pl.len()).collect().item()\n",
    "\n",
    "print(f\"311-service-requests.csv: {n:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd0da1-96de-4ff4-90b6-17ae5f2cce04",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Next a query is created to perform a set of transformations on the dataset. The example in the next cell aggregates service requests by type, year, month and quantized longitude and latitude using 0.005 degree bins. Since we're using a LazyFrame, no action will be taken until `.collect()` is called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd11a667-b3c6-4f90-b2e2-b972ac46aa39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:17:50.007050Z",
     "iopub.status.busy": "2025-10-30T03:17:50.006843Z",
     "iopub.status.idle": "2025-10-30T03:17:50.011397Z",
     "shell.execute_reply": "2025-10-30T03:17:50.010901Z",
     "shell.execute_reply.started": "2025-10-30T03:17:50.007034Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "query = (\n",
    "    lf\n",
    "    .select([\n",
    "        pl.col(\"Borough\").alias(\"borough\"),\n",
    "        pl.col(\"Complaint Type\").alias(\"type\"),\n",
    "        pl.col(\"Latitude\").alias(\"lat\"),\n",
    "        pl.col(\"Longitude\").alias(\"lon\"),\n",
    "        pl.col(\"year\").cast(pl.Int16),\n",
    "        pl.col(\"month\").cast(pl.Int8),\n",
    "    ])\n",
    "    .filter(\n",
    "          pl.col(\"borough\").is_not_null() &\n",
    "          pl.col(\"type\").is_not_null() &\n",
    "          pl.col(\"lat\").is_not_null() &\n",
    "          pl.col(\"lon\").is_not_null() &\n",
    "          (pl.col(\"lat\").abs() > 0) &\n",
    "          (pl.col(\"lon\").abs() > 0)\n",
    "      )\n",
    "    # Quantize to 0.005 degree bins.\n",
    "    .with_columns([\n",
    "        (pl.col(\"lat\") * 200).floor().cast(pl.Int32).alias(\"lat_bin\"),\n",
    "        (pl.col(\"lon\") * 200).floor().cast(pl.Int32).alias(\"lon_bin\"),\n",
    "    ])\n",
    "    .group_by([\"year\", \"month\", \"lat_bin\", \"lon_bin\", \"type\"])\n",
    "    .agg([\n",
    "        pl.len().alias(\"n\"),\n",
    "     ])\n",
    "    .sort(\"n\", descending=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fd424-de6a-4912-a27a-cdcb3ffe8f66",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "First the standard Polars CPU engine is benchmarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72bfa128-bf0f-4af8-bba8-b6b8c9eec34e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:18:46.654916Z",
     "iopub.status.busy": "2025-10-30T03:18:46.654701Z",
     "iopub.status.idle": "2025-10-30T03:18:53.383774Z",
     "shell.execute_reply": "2025-10-30T03:18:53.383248Z",
     "shell.execute_reply.started": "2025-10-30T03:18:46.654900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime using CPU: 6.72 seconds.\n",
      "\n",
      "df.shape: (71133, 6).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>lat_bin</th><th>lon_bin</th><th>type</th><th>n</th></tr><tr><td>i16</td><td>i8</td><td>i32</td><td>i32</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>2019</td><td>9</td><td>8138</td><td>-14786</td><td>&quot;Noise - Residential&quot;</td><td>81966</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Illegal Parking&quot;</td><td>69024</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Noise - Vehicle&quot;</td><td>69024</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "┌──────┬───────┬─────────┬─────────┬─────────────────────┬───────┐\n",
       "│ year ┆ month ┆ lat_bin ┆ lon_bin ┆ type                ┆ n     │\n",
       "│ ---  ┆ ---   ┆ ---     ┆ ---     ┆ ---                 ┆ ---   │\n",
       "│ i16  ┆ i8    ┆ i32     ┆ i32     ┆ str                 ┆ u32   │\n",
       "╞══════╪═══════╪═════════╪═════════╪═════════════════════╪═══════╡\n",
       "│ 2019 ┆ 9     ┆ 8138    ┆ -14786  ┆ Noise - Residential ┆ 81966 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Illegal Parking     ┆ 69024 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Noise - Vehicle     ┆ 69024 │\n",
       "└──────┴───────┴─────────┴─────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "t_init = time.time()\n",
    "df = query.collect()\n",
    "t_total = time.time() - t_init\n",
    "\n",
    "print(f\"Total runtime using CPU: {t_total:,.2f} seconds.\\n\")\n",
    "print(f\"df.shape: {df.shape}.\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d73694-6260-4f86-96e7-6fc72cff2f34",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Next the query is executed against the GPU engine. The only difference from the previous cell is `engine=\"gpu\"` is passed into `.collect()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbac9ec-2ce9-4164-bf21-e0a77acbfe64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:19:11.888867Z",
     "iopub.status.busy": "2025-10-30T03:19:11.888593Z",
     "iopub.status.idle": "2025-10-30T03:19:12.236316Z",
     "shell.execute_reply": "2025-10-30T03:19:12.235859Z",
     "shell.execute_reply.started": "2025-10-30T03:19:11.888851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime using GPU engine: 0.34 seconds.\n",
      "\n",
      "df2.shape: (71133, 6).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>lat_bin</th><th>lon_bin</th><th>type</th><th>n</th></tr><tr><td>i16</td><td>i8</td><td>i32</td><td>i32</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>2019</td><td>9</td><td>8138</td><td>-14786</td><td>&quot;Noise - Residential&quot;</td><td>81966</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Illegal Parking&quot;</td><td>69024</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Noise - Vehicle&quot;</td><td>69024</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "┌──────┬───────┬─────────┬─────────┬─────────────────────┬───────┐\n",
       "│ year ┆ month ┆ lat_bin ┆ lon_bin ┆ type                ┆ n     │\n",
       "│ ---  ┆ ---   ┆ ---     ┆ ---     ┆ ---                 ┆ ---   │\n",
       "│ i16  ┆ i8    ┆ i32     ┆ i32     ┆ str                 ┆ u32   │\n",
       "╞══════╪═══════╪═════════╪═════════╪═════════════════════╪═══════╡\n",
       "│ 2019 ┆ 9     ┆ 8138    ┆ -14786  ┆ Noise - Residential ┆ 81966 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Illegal Parking     ┆ 69024 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Noise - Vehicle     ┆ 69024 │\n",
       "└──────┴───────┴─────────┴─────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Execute query with GPU engine.\n",
    "t_init = time.time()\n",
    "df2 = query.collect(engine=\"gpu\")\n",
    "t_total = time.time() - t_init\n",
    "\n",
    "print(f\"Total runtime using GPU engine: {t_total:,.2f} seconds.\\n\")\n",
    "print(f\"df2.shape: {df2.shape}.\")\n",
    "df2.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a4619-2545-40c3-a18d-2bac6976a0b5",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Using the CPU engine took 6.72 seconds, vs. 0.34 seconds for the GPU engine, or a ~20x speedup. This is an incredible performance gain that required no code changes. \n",
    "\n",
    "One thing to mention: When `engine=\"gpu\"` is specified, if an operation is not supported on GPU, the query will silently fallback to CPU execution, which can make benchmarking tricky. To have Polars fail loudly if part of a query cannot be executed on GPU, we can pass a `GPUEngine` object inplace of `\"gpu\"` in the call to `.collect()`. If `raise_on_fail` is set True, any non-GPU supported operations will cause the entire pipeline to fail. The next cell shows what this would look like (not the failure, but creating a `GPUEngine` object): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec60d08-8a92-4106-a27e-b40b44385ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T03:20:33.470727Z",
     "iopub.status.busy": "2025-10-30T03:20:33.470520Z",
     "iopub.status.idle": "2025-10-30T03:20:33.822946Z",
     "shell.execute_reply": "2025-10-30T03:20:33.822492Z",
     "shell.execute_reply.started": "2025-10-30T03:20:33.470711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>lat_bin</th><th>lon_bin</th><th>type</th><th>n</th></tr><tr><td>i16</td><td>i8</td><td>i32</td><td>i32</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>2019</td><td>9</td><td>8138</td><td>-14786</td><td>&quot;Noise - Residential&quot;</td><td>81966</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Illegal Parking&quot;</td><td>69024</td></tr><tr><td>2019</td><td>9</td><td>8144</td><td>-14762</td><td>&quot;Noise - Vehicle&quot;</td><td>69024</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "┌──────┬───────┬─────────┬─────────┬─────────────────────┬───────┐\n",
       "│ year ┆ month ┆ lat_bin ┆ lon_bin ┆ type                ┆ n     │\n",
       "│ ---  ┆ ---   ┆ ---     ┆ ---     ┆ ---                 ┆ ---   │\n",
       "│ i16  ┆ i8    ┆ i32     ┆ i32     ┆ str                 ┆ u32   │\n",
       "╞══════╪═══════╪═════════╪═════════╪═════════════════════╪═══════╡\n",
       "│ 2019 ┆ 9     ┆ 8138    ┆ -14786  ┆ Noise - Residential ┆ 81966 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Illegal Parking     ┆ 69024 │\n",
       "│ 2019 ┆ 9     ┆ 8144    ┆ -14762  ┆ Noise - Vehicle     ┆ 69024 │\n",
       "└──────┴───────┴─────────┴─────────┴─────────────────────┴───────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fail loudly if can't execute on the GPU.\n",
    "gpu_engine = pl.GPUEngine(device=0,  raise_on_fail=True)  \n",
    "df2 = query.collect(engine=gpu_engine)\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5479525-db83-42d0-b8e0-82877887953f",
   "metadata": {},
   "source": [
    "Since all the operations in our query are GPU supported, no error is thrown. \n",
    "\n",
    "Another tip for monitoring GPU usage for longer running jobs: From the terminal, run `nvidia-smi -l 1`, which refreshes the output `nvidia-smi` every second. The expectation is that if the GPU is being utilized, the amount of VRAM in use should change over time. \n",
    "\n",
    "GPU-enabled Polars pushes analytical performance to a new level. For large, computation-heavy workloads (joins, group-bys, and sorts across tens or hundreds of millions of rows), the GPU engine can deliver dramatic speedups without changing a single line of code. That said, not everything is supported on GPU yet. Operations like complex datetime handling, regex, or window functions may fall back to CPU, and for smaller or I/O-heavy jobs the extra GPU overhead can actually slow things down. But as datasets continue to grow and GPU coverage expands, the ability to execute entire analytical pipelines directly in VRAM opens the door to running truly large-scale analytics on a single machine, turning what used to require distributed infrastructure into something you can do from your laptop. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
