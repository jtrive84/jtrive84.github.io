{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Derivation of the Normal Equations \n",
    "date: 2024-02-01\n",
    "description: Derivation of the Normal Equations via least squares and maximum likelihood  \n",
    "categories: [Statistical Modeling]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Normal Equations, represented in matrix form as  \n",
    "\n",
    "$$\n",
    "(X^{T}X)\\hat{\\beta} = X^{T}y\n",
    "$$\n",
    "\n",
    "are utilized in determining coefficient estimates associated with regression \n",
    "models. The matrix form is a compact representation of the model specification \n",
    "commonly represented as\n",
    "\n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\cdots + \\beta_{k}x_{k} + \\varepsilon\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ represents the error term, and\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\varepsilon_{i} = 0.\n",
    "$$\n",
    "\n",
    "For a dataset with $n$ records by $k$ explanatory variables per record, the \n",
    "components of the Normal Equations are:\n",
    "\n",
    "- $\\hat{\\beta} = (\\hat{\\beta}_{0},\\hat{\\beta}_{1},\\cdots,\\hat{\\beta}_{k})^{T}$, a \n",
    "vector of $(k+1)$ coefficents (one for each of the k explanatory variables plus \n",
    "one for the intercept term)     \n",
    "- $X$ , an $n$ by $(k+1)$-dimensional matrix of explanatory variables, with the \n",
    "first column consisting entirely of 1â€™s   \n",
    "- ${y} = (y_{1}, y_{2},...,y_{n})$, the response     \n",
    "\n",
    "\n",
    "The task is to solve for the $(k+1)$ $\\beta_{j}$'s such that $\\hat{\\beta}_{0}, \\hat{\\beta}_{1},...,\\hat{\\beta}_{k}$ minimize  \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\hat{\\varepsilon}^{2}_{i} = \\sum_{i=1}^{n} (y_{i} - \\hat{\\beta}_{0} - \\hat{\\beta}_{1}x_{i1} - \\hat{\\beta}_{2}x_{i2} - \\cdots - \\hat{\\beta}_{k}x_{ik})^2.\n",
    "$$\n",
    "\n",
    "\n",
    "The Normal Equations can be derived using Least-Squares and Maximum likelihood \n",
    "Estimation. \n",
    "\n",
    "### Least-Squares Derivation\n",
    "\n",
    "Unlike Maximum Likelihood derivation, the Least-Squares approach requires no \n",
    "distributional assumption. For \n",
    "$\\hat{\\beta}_{0}, \\hat{\\beta}_{1}, \\cdots ,\\hat{\\beta}_{k}$, we seek estimators that \n",
    "minimize the sum of squared deviations between the $n$ response values and \n",
    "the predicted values, $\\hat{y}$. The objective is to minimize\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\hat{\\varepsilon}^{2}_{i} = \\sum_{i=1}^{n} (y_{i} - \\hat{\\beta}_{0} - \\hat{\\beta}_{1}x_{i1} - \\hat{\\beta}_{2}x_{i2} - \\cdots - \\hat{\\beta}_{k}x_{ik})^2.\n",
    "$$\n",
    "\n",
    "\n",
    "Using matrix notation, our model can be represented as \n",
    "$y = X^{T}\\beta + \\varepsilon$. Isolating and squaring the error term yields\n",
    "\n",
    "$$\n",
    "\\hat \\varepsilon^T \\hat \\varepsilon =  \\sum_{i=1}^{n} (y - X\\hat{\\beta})^{T}(y - X\\hat{\\beta}).\n",
    "$$\n",
    "\n",
    "Expanding the right-hand side and combining terms results in\n",
    "\n",
    "$$\n",
    "\\hat \\varepsilon^T \\hat \\varepsilon = y^{T}y - 2y^{T}X\\hat{\\beta} + \\hat{\\beta}X^{T}X\\hat{\\beta}\n",
    "$$\n",
    "\n",
    "To find the value of $\\hat{\\beta}$ that minimizes \n",
    "$\\hat \\varepsilon^T \\hat \\varepsilon$, we differentiate \n",
    "$\\hat \\varepsilon^T \\hat \\varepsilon$ with respect to $\\hat{\\beta}$, and set \n",
    "the result to zero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{\\varepsilon}^{T}\\hat{\\varepsilon}}{\\partial \\hat{\\beta}} = -2X^{T}y + 2X^{T}X\\hat{\\beta} = 0\n",
    "$$\n",
    "\n",
    "Which can then be solved for $\\hat{\\beta}$:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = {(X^{T}X)}^{-1}{X}^{T}y\n",
    "$$\n",
    "\n",
    "\n",
    "Since $\\hat{\\beta}$ minimizes the sum of squares, $\\hat{\\beta}$ is called the \n",
    "*Least-Squares Estimator*.\n",
    "\n",
    "\n",
    "### Maximum Likelihood Derivation\n",
    "For the Maximum Likelihood derivation, $X$, $y$ and $\\hat{\\beta}$ are the same \n",
    "as described in the Least-Squares derivation, and the model still follows the \n",
    "form\n",
    "\n",
    "$$\n",
    "y = X^{T}\\beta + \\varepsilon\n",
    "$$\n",
    "\n",
    "but now we assume the $\\varepsilon_{i}$ are $iid$ and follow a zero-mean normal \n",
    "distribution:\n",
    "\n",
    "$$\n",
    "N(\\varepsilon_{i}; 0, \\sigma^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} e^{- \\frac{(y_{i}-X^{T}\\hat{\\beta})^{2}}{2\\sigma^{2}}}.\n",
    "$$\n",
    "\n",
    "In addition, the responses, $y_{i}$, are each assumed to follow a normal \n",
    "distribution. For $n$ observations, the likelihood function is\n",
    "\n",
    "$$\n",
    "L(\\beta) = \\Big(\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\Big)^{n} e^{-(y-X\\beta)^{T}(y-X\\beta)/2\\sigma^{2}}.\n",
    "$$\n",
    "\n",
    "The Log-Likelihood is then\n",
    "\n",
    "$$\n",
    "\\mathrm{Ln}(L(\\beta)) = -\\frac{n}{2}\\mathrm{Ln}(2\\pi) -\\frac{n}{2}\\mathrm{Ln}(\\sigma^{2})-\\frac{1}{2\\sigma^{2}}(y-X\\beta)^{T}(y-X\\beta).\n",
    "$$\n",
    "\n",
    "Taking derivatives with respect to $\\beta$ and setting the result equal to zero \n",
    "yields\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{Ln}(L(\\beta))}{\\partial \\beta} = -2X^{T}y -2X^{T}X\\beta = 0.\n",
    "$$\n",
    "\n",
    "Rearranging and solving for $\\beta$ we obtain\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = {(X^{T}X)}^{-1}{X}^{T}y,\n",
    "$$\n",
    "\n",
    "which is the same result obtained via Least Squares.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
