<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-02-28">
<meta name="description" content="Backpropagation for fully-connected neural networks">

<title>Backpropagation for Fully-Connected Neural Networks – The Pleasure of Finding Things Out: A blog by James Triveri</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">The Pleasure of Finding Things Out: A blog by James Triveri</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jtrive84/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jamestriveri/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://python-bloggers.com/"> <i class="bi bi-p-square" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Backpropagation for Fully-Connected Neural Networks</h1>
                  <div>
        <div class="description">
          Backpropagation for fully-connected neural networks
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Python</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 28, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Backpropagation is a key algorithm used in training fully connected neural networks, also known as feed-forward neural networks. In this algorithm, the network’s output error is propagated backward, layer by layer, to adjust the weights of connections between neurons.</p>
<p><img src="fc.png" class="img-fluid"></p>
<p>The process starts by comparing the network’s output to the desired output, calculating the error. Then, starting from the output layer and moving backward, the algorithm computes the gradients of the error with respect to each weight in the network using the chain rule of calculus. These gradients indicate how much each weight contributes to the error.</p>
<p>Next, the weights are updated using gradient descent, where they are adjusted in the direction that minimizes the error. This adjustment is proportional to the gradient and a predefined learning rate, ensuring the network converges towards a solution. Backpropagation continues iteratively over the training data until the network’s performance reaches a satisfactory level or a predetermined number of iterations is reached.</p>
<p>Overall, backpropagation efficiently adjusts the weights of a fully connected network, enabling it to learn complex relationships between input and output data through iterative optimization of the network’s parameters.</p>
<p>In what follows, we walkthrough the mathematics and pseudocode required to train a 2-layer fully connected network for a classification task.</p>
<section id="forward-pass" class="level3">
<h3 class="anchored" data-anchor-id="forward-pass">Forward Pass</h3>
<p>In the following, superscripts represent the layer associated with each variable:</p>
<ul>
<li><p><span class="math inline">\(X = A^{(0)}\)</span>: Input data having dimension n-by-f, where n is the number of samples and f the number of features. For a batch of 32 MNIST samples, <span class="math inline">\(X\)</span> would have dimension (32, 784).</p></li>
<li><p><span class="math inline">\(y\)</span>: Target variable. classifying a single digit from MINST, a vector populated with 0s and 1s indicating the ground truth label for the sample (8 or not 8). Has the same length as the first dimension of <span class="math inline">\(X\)</span>.</p></li>
<li><p><span class="math inline">\(W^{(l)}\)</span>: Trainable weights. Projects previous layer activations to lower dimensional representation. Again referring to the first set of weights for a batch of 32 MNIST samples, <span class="math inline">\(W^{(1)}\)</span>’s first dimension will match the second dimension of the activations from the previous layer (784), and <span class="math inline">\(W^{(1)}\)</span>’s second dimension will be some lower dimension, say 256. <span class="math inline">\(W^{(1)}\)</span> will therefore have dimension (784, 256).</p></li>
<li><p><span class="math inline">\(b^{(l)}\)</span>: Bias term, a one-dimensional vector associated with each hidden layer having length equal to the second dimension of the hidden layer. <span class="math inline">\(b^{(1)}\)</span> will have dimension (256,).</p></li>
<li><p><span class="math inline">\(Z^{(l)} = A^{(l-1)} W^{(l)} + b^{(l)}\)</span>: Output of layer <span class="math inline">\(l\)</span>, which is the matrix product of the previous layer activations <span class="math inline">\(A^{(l-1)}\)</span> and current layer weights (plus bias term).</p></li>
<li><p><span class="math inline">\(A^{(l)} = \sigma(Z^{(l)})\)</span>: Activations associated with layer <span class="math inline">\(l\)</span>. Passes <span class="math inline">\(Z^{(l)}\)</span> through a non-linearity such as sigmoid or ReLU.</p></li>
</ul>
<p>More concretely, assume a 2-layer fully-connected neural network with one hidden layer of size 256, through which a dataset of dimension 32-by-784 is passed to predict whether each of the 32 images is an 8 or not. The forward pass looks like:</p>
<ul>
<li>Randomly initialize <span class="math inline">\(W^{(1)}\)</span> (784x256), <span class="math inline">\(W^{(2)}\)</span> (256x1), <span class="math inline">\(b^{(1)}\)</span> (256x1) and <span class="math inline">\(b^{(2)}\)</span> (1x1)</li>
<li><span class="math inline">\(X = A^{(0)}\hspace{.75em}\)</span> (32x784)</li>
<li><span class="math inline">\(Z^{(1)} = A^{(0)} W^{(1)} + b^{(1)}\hspace{.75em}\)</span> (32x256)</li>
<li><span class="math inline">\(A^{1} = \sigma(Z^{(1)})\hspace{.75em}\)</span> (32x256)</li>
<li><span class="math inline">\(Z^{(2)} = A^{(1)} W^{(2)} + b^{(2)}\hspace{.75em}\)</span> (32x1)</li>
<li><span class="math inline">\(\hat{y} = A^{(2)} = \sigma(Z^{(2)})\hspace{.75em}\)</span> (32x1)</li>
</ul>
<p>The final output, <span class="math inline">\(\hat{y}\)</span>, represents the probability that each sample is the number 8 or not.</p>
<p>With the actual labels <span class="math inline">\(y\)</span> and our predicted probabilities <span class="math inline">\(\hat{y}\)</span>, we can define our loss function, the cross-entropy loss for binary classification:</p>
<p><span class="math display">\[
\mathcal{L} = -\frac{1}{n}\big(y \times \mathrm{log}(\hat{y}) - (1 - y)\times \mathrm{log}(1 - \hat{y})\big)
\]</span></p>
</section>
<section id="backward-pass-backpropagation" class="level3">
<h3 class="anchored" data-anchor-id="backward-pass-backpropagation">Backward Pass (Backpropagation)</h3>
<p>The goal of backpropagation is to compute the partial derivatives of the loss function <span class="math inline">\(\mathcal{L}\)</span> with respect to any weight <span class="math inline">\(W\)</span> or <span class="math inline">\(b\)</span> in the network. In order to update our weights, we need to take derivatives of <span class="math inline">\(\mathcal{L}\)</span> w.r.t. <span class="math inline">\(W\)</span> and <span class="math inline">\(b\)</span>, then update <span class="math inline">\(W\)</span> and <span class="math inline">\(b\)</span> using the derivatives. Backpropagation starts by taking the derivative of the loss function. We first compute the derivatives of the loss function w.r.t. <span class="math inline">\(W^{(2)}\)</span> and <span class="math inline">\(b^{(2)}\)</span>. Here we make use of the chain rule:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial W^{(2)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial W^{(2)}}\\
\frac{\partial \mathcal{L}}{\partial b^{(2)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial b^{(2)}}
\end{align*}
\]</span></p>
<p>Once we have <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial W^{(2)}}\)</span> and <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial b^{(2)}}\)</span>, <span class="math inline">\(W^{(2)}\)</span> and <span class="math inline">\(b^{(2)}\)</span> are updated as follows:</p>
<p><span class="math display">\[
\begin{align*}
W^{(2)} &amp;:= W^{(2)} - \alpha \cdot \frac{\partial \mathcal{L}}{\partial W^{(2)}}\\
b^{(2)} &amp;:= b^{(2)} - \alpha \cdot \frac{\partial \mathcal{L}}{\partial b^{(2)}}
\end{align*}
\]</span></p>
<p>for some learning rate <span class="math inline">\(\alpha\)</span>. This holds for all layers. For given layer <span class="math inline">\(i\)</span>, the update rule for <span class="math inline">\(W^{(i)}\)</span> and <span class="math inline">\(b^{(i)}\)</span> is:</p>
<p><span class="math display">\[
\begin{align*}
W^{(i)} &amp;:= W^{(i)} - \alpha \cdot \frac{\partial \mathcal{L}}{\partial W^{(i)}}\\
b^{(i)} &amp;:= b^{(i)} - \alpha \cdot \frac{\partial \mathcal{L}}{\partial b^{(i)}}.
\end{align*}
\]</span></p>
<p>Let’s start with unpacking <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial W^{(2)}}\)</span>. The first entry on the r.h.s., <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial A^{(2)}}\)</span>, represents the derivative of the loss function w.r.t. <span class="math inline">\(A^{(2)} = \hat{y}\)</span>, which is</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial A^{(2)}} = -\frac{y}{A^{(2)}} + \frac{1 - y}{1 - A^{(2)}}.
\]</span></p>
<p>The second term on the r.h.s., <span class="math inline">\(\frac{\partial A^{(2)}}{\partial Z^{(2)}}\)</span>, is the derivative of the sigmoid activation (<span class="math inline">\(A^{(2)} = \sigma(Z^{(2)})\)</span>). The derivative of the sigmoid function is given by</p>
<p><span class="math display">\[
\frac{d\sigma}{dx} = \sigma(x)(1-\sigma(x)),
\]</span></p>
<p>therefore <span class="math inline">\(\frac{\partial A^{(2)}}{\partial Z^{(2)}}\)</span> is given by</p>
<p><span class="math display">\[
\frac{\partial A^{(2)}}{\partial Z^{(2)}} = A^{(2)}(1 - A^{(2)}).
\]</span></p>
<p>For the third term on the r.h.s., <span class="math inline">\(\frac{\partial Z^{(2)}}{\partial W^{(2)}}\)</span>, recall that <span class="math inline">\(Z^{(2)} = A^{(1)} W^{(2)} + b^{(2)}\)</span>. Therefore</p>
<p><span class="math display">\[
\frac{\partial Z^{(2)}}{\partial W^{(2)}} = A^{(1)}.
\]</span></p>
<p>Finally, we have</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial W^{(2)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial W^{(2)}}\\
&amp;= \Big(-\frac{y}{A^{(2)}} + \frac{1 - y}{1 - A^{(2)}}\Big) \cdot \big(A^{(2)}(1 - A^{(2)})\big) \cdot \big(A^{(1)}\big)\\
&amp;= (A^{(2)} - y) \cdot A^{(1)}.
\end{align*}
\]</span></p>
<p>As a notational convenience, we define <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial Z^{(2)}}\)</span>:</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial Z^{(2)}} = \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} = (A^{(2)} - y).
\]</span></p>
<p>This way, <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial W^{(2)}}\)</span> can be expressed as</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial W^{(2)}} = \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot A^{(1)}.
\]</span></p>
<p>We proceed in a similar fashion for <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial b^{(2)}}\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial b^{(2)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial b^{(2)}}\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial b^{(2)}}\\
&amp;= (A^{(2)} - y),
\end{align*}
\]</span></p>
<p>since <span class="math inline">\(\frac{\partial Z^{(2)}}{\partial b^{(2)}} = 1\)</span>.</p>
<p>For the first layer we re-use many of these calculations, but for new terms on the r.h.s., we employ the chain rule in the same way. For reference, restate the terms from the forward pass:</p>
<p><span class="math display">\[
\begin{align*}
A^{(0)} &amp;= X\\
Z^{(1)} &amp;= A^{(0)} W^{(1)} + b^{(1)}\\
A^{1} &amp;= \sigma(Z^{(1)})\\
Z^{(2)} &amp;= A^{(1)} W^{(2)} + b^{(2)}\\
A^{(2)} &amp;= \hat{y} = \sigma(Z^{(2)})
\end{align*}
\]</span></p>
<p>We next consider <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial W^{(1)}}\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial W^{(1)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial A^{(1)}} \cdot \frac{\partial A^{(1)}}{\partial Z^{(1)}} \cdot \frac{\partial Z^{(1)}}{\partial W^{(1)}}\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial A^{(1)}} \cdot \frac{\partial A^{(1)}}{\partial Z^{(1)}} \cdot \frac{\partial Z^{(1)}}{\partial W^{(1)}}
\end{align*}
\]</span></p>
<p>Considering each term on the r.h.s:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial Z^{(2)}} &amp;= (A^{(2)} - y)\\
\frac{\partial Z^{(2)}}{\partial A^{(1)}} &amp;= W^{(2)}\\
\frac{\partial A^{(1)}}{\partial Z^{(1)}} &amp;= \sigma(Z^{(1)}) (1 - \sigma(Z^{(1)})) = A^{(1)}(1 - A^{(1)})\\
\frac{\partial Z^{(1)}}{\partial W^{(1)}} &amp;= A^{(0)} = X
\end{align*}
\]</span></p>
<p>Resulting in:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial W^{(1)}} &amp;= (A^{(2)} - y) \cdot W^{(2)} \cdot \big(A^{(1)}(1 - A^{(1)})\big) \cdot A^{(0)}\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(2)}}\cdot W^{(2)} \cdot \big(A^{(1)}(1 - A^{(1)})\big) \cdot A^{(0)}\\
\end{align*}
\]</span></p>
<p>As before, we define <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial Z^{(1)}}\)</span> as</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial Z^{(1)}} = \frac{\partial \mathcal{L}}{\partial Z^{(2)}}\cdot W^{(2)} \cdot \big(A^{(1)}(1 - A^{(1)})\big),
\]</span></p>
<p>which allows us to write <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial W^{(1)}}\)</span> as</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial W^{(1)}} = \frac{\partial \mathcal{L}}{\partial Z^{(1)}} \cdot A^{(0)}.
\]</span></p>
<p>Similarly for <span class="math inline">\(b^{(1)}\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial b^{(1)}} &amp;= \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial A^{(1)}} \cdot \frac{\partial A^{(1)}}{\partial Z^{(1)}} \cdot \frac{\partial Z^{(1)}}{\partial b^{(1)}}\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial A^{(1)}} \cdot \frac{\partial A^{(1)}}{\partial Z^{(1)}} \cdot \frac{\partial Z^{(1)}}{\partial b^{(1)}}.
\end{align*}
\]</span></p>
<p>Considering each term on the r.h.s:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial Z^{(2)}} &amp;= (A^{(2)} - y)\\
\frac{\partial Z^{(2)}}{\partial A^{(1)}} &amp;= W^{(2)}\\
\frac{\partial A^{(1)}}{\partial Z^{(1)}} &amp;= \sigma(Z^{(1)}) (1 - \sigma(Z^{(1)})) = A^{(1)}(1 - A^{(1)})\\
\frac{\partial Z^{(1)}}{\partial b^{(1)}} &amp;= 1
\end{align*}
\]</span></p>
<p>Therefore</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial \mathcal{L}}{\partial b^{(1)}} &amp;= (A^{(2)} - y) \cdot W^{(2)} \cdot \big(A^{(1)}(1 - A^{(1)})\big) \cdot 1\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot W^{(2)} \cdot \big(A^{(1)}(1 - A^{(1)})\big)\\
&amp;= \frac{\partial \mathcal{L}}{\partial Z^{(1)}}.
\end{align*}
\]</span></p>
<p>To complete the backpropagation algorithm, it is necessary to define <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial A^{(1)}}\)</span>:</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial A^{(1)}} = \frac{\partial \mathcal{L}}{\partial A^{(2)}} \cdot \frac{\partial A^{(2)}}{\partial Z^{(2)}} \cdot \frac{\partial Z^{(2)}}{\partial A^{(1)}} = \frac{\partial \mathcal{L}}{\partial Z^{(2)}} \cdot W^{(2)}.
\]</span></p>
<p>Assume <span class="math inline">\(X\)</span> is a 32x784 batch of MNIST images, and our network has one hidden layer of size 256. Our task is to identify which digit 0-9 a sample most closely resembles. We first declare a number of functions, then implement the forward and backward passes along with weights update.</p>
<div id="b0bf5cc5" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(X):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the sigmoid activation for the input.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>X))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid_dev(X):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">    The analytical derivative of sigmoid function at X.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sigmoid(X) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> sigmoid(X))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(scores):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute softmax scores given the raw output from the model.</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns softmax probabilities (N, num_classes).</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    numer <span class="op">=</span> np.exp(scores <span class="op">-</span> scores.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> numer.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.divide(numer, denom)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy_loss(ypred, yactual):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute Cross-Entropy Loss based on prediction of the network and labels</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    yactual <span class="op">=</span> np.asarray(yactual)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    ypred <span class="op">=</span> ypred[np.arange(<span class="bu">len</span>(yactual)), yactual]</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.mean(np.log(ypred))</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy(ypred, yactual):</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the accuracy of current batch.</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    yactual <span class="op">=</span> np.asarray(yactual)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> np.argmax(ypred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (y <span class="op">==</span> yhat).<span class="bu">sum</span>() <span class="op">/</span> y.shape[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="83a0efc0" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Stand in for batch of 32 MNIST images. </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">256</span>, size<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">784</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">10</span>, size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape labels to 32 x 10. </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.zeros((<span class="dv">32</span>, <span class="dv">10</span>))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>Y[np.arange(X.shape[<span class="dv">0</span>]), y] <span class="op">=</span> <span class="dv">1</span>  <span class="co"># (32, 10)</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate.</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">.05</span> </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize weights.</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> np.zeros(<span class="dv">256</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> np.zeros(<span class="dv">10</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> <span class="fl">0.001</span> <span class="op">*</span> np.random.randn(<span class="dv">784</span>, <span class="dv">256</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> <span class="fl">0.001</span> <span class="op">*</span> np.random.randn(<span class="dv">256</span>, <span class="dv">10</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass.</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>Z1 <span class="op">=</span> X <span class="op">@</span> W1 <span class="op">+</span> b1   <span class="co"># (32, 256)</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>A1 <span class="op">=</span> sigmoid(Z1)   <span class="co"># (32, 256)</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>Z2 <span class="op">=</span> A1 <span class="op">@</span> W2 <span class="op">+</span> b2  <span class="co"># (32, 10)</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>A2 <span class="op">=</span> softmax(Z2)   <span class="co"># (32, 10)</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute loss and accuracy.</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> cross_entropy_loss(A2, y)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> compute_accuracy(A2, y)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Backward pass.</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>dZ2 <span class="op">=</span> A2 <span class="op">-</span> Y                            <span class="co"># (32, 10)</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>dW2 <span class="op">=</span> (A1.T <span class="op">@</span> dZ2) <span class="op">/</span> <span class="dv">32</span>                 <span class="co"># (256, 10)</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>db2 <span class="op">=</span> np.<span class="bu">sum</span>(dZ2, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="dv">32</span>          <span class="co"># (10,)</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>dA1 <span class="op">=</span> dZ2 <span class="op">@</span> W2.T                        <span class="co"># (32, 256)</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>dZ1 <span class="op">=</span> np.multiply(dA1, sigmoid_dev(Z1)) <span class="co"># (32, 256)</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>dW1 <span class="op">=</span> (X.T <span class="op">@</span> dZ1) <span class="op">/</span> <span class="dv">32</span>                  <span class="co"># (784, 256)</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>db1 <span class="op">=</span> np.<span class="bu">sum</span>(dZ1, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="dv">32</span>          <span class="co"># (256,)</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Update weights.</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> W2 <span class="op">-</span> alpha <span class="op">*</span> dW2</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> b2 <span class="op">-</span> alpha <span class="op">*</span> db2</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> W1 <span class="op">-</span> alpha <span class="op">*</span> dW1</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> b1 <span class="op">-</span> alpha <span class="op">*</span> db1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code starting with the forward pass would be iterated over a set of batches for a pre-determined number of epochs. The final weights would then be used for inference.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.jtrive\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>